{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEG Learn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdoJ8rQ2UWPh",
        "colab_type": "text"
      },
      "source": [
        "# 1. Utils (copied from the repository)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPwpQI8e38Nc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io\n",
        "import math\n",
        "import numpy as np\n",
        "from functools import reduce\n",
        "from scipy.interpolate import griddata\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, LSTM, Concatenate\n",
        "from tensorflow.keras.layers import Input, TimeDistributed, Reshape, MaxPooling1D, Permute, Conv1D, BatchNormalization\n",
        "from tensorflow.keras.constraints import Constraint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def cart2sph(x, y, z):\n",
        "    \"\"\"\n",
        "    Transform Cartesian coordinates to spherical\n",
        "    :param x: X coordinate\n",
        "    :param y: Y coordinate\n",
        "    :param z: Z coordinate\n",
        "    :return: radius, elevation, azimuth\n",
        "    \"\"\"\n",
        "    x2_y2 = x**2 + y**2\n",
        "    r = math.sqrt(x2_y2 + z**2)                    # r\n",
        "    elev = math.atan2(z, math.sqrt(x2_y2))         # Elevation\n",
        "    az = math.atan2(y, x)                          # Azimuth\n",
        "    return r, elev, az\n",
        "\n",
        "\n",
        "def pol2cart(theta, rho):\n",
        "    \"\"\"\n",
        "    Transform polar coordinates to Cartesian\n",
        "    :param theta: angle value\n",
        "    :param rho: radius value\n",
        "    :return: X, Y\n",
        "    \"\"\"\n",
        "    return rho * math.cos(theta), rho * math.sin(theta)\n",
        "\n",
        "\n",
        "def azim_proj(pos):\n",
        "    \"\"\"\n",
        "    Computes the Azimuthal Equidistant Projection of input point in 3D Cartesian Coordinates.\n",
        "    Imagine a plane being placed against (tangent to) a globe. If\n",
        "    a light source inside the globe projects the graticule onto\n",
        "    the plane the result would be a planar, or azimuthal, map\n",
        "    projection.\n",
        "\n",
        "    :param pos: position in 3D Cartesian coordinates\n",
        "    :return: projected coordinates using Azimuthal Equidistant Projection\n",
        "    \"\"\"\n",
        "    [r, elev, az] = cart2sph(pos[0], pos[1], pos[2])\n",
        "    return pol2cart(az, math.pi / 2 - elev)\n",
        "\n",
        "def gen_images(locs, features, n_gridpoints, normalize=True,\n",
        "               augment=False, pca=False, std_mult=0.1, n_components=2, edgeless=False):\n",
        "    \"\"\"\n",
        "    Generates EEG images given electrode locations in 2D space and multiple feature values for each electrode\n",
        "\n",
        "    :param locs: An array with shape [n_electrodes, 2] containing X, Y\n",
        "                        coordinates for each electrode.\n",
        "    :param features: Feature matrix as [n_samples, n_features]\n",
        "                                Features are as columns.\n",
        "                                Features corresponding to each frequency band are concatenated.\n",
        "                                (alpha1, alpha2, ..., beta1, beta2,...)\n",
        "    :param n_gridpoints: Number of pixels in the output images\n",
        "    :param normalize:   Flag for whether to normalize each band over all samples\n",
        "    :param augment:     Flag for generating augmented images\n",
        "    :param pca:         Flag for PCA based data augmentation\n",
        "    :param std_mult     Multiplier for std of added noise\n",
        "    :param n_components: Number of components in PCA to retain for augmentation\n",
        "    :param edgeless:    If True generates edgeless images by adding artificial channels\n",
        "                        at four corners of the image with value = 0 (default=False).\n",
        "    :return:            Tensor of size [samples, colors, W, H] containing generated\n",
        "                        images.\n",
        "    \"\"\"\n",
        "    feat_array_temp = []\n",
        "    nElectrodes = locs.shape[0]     # Number of electrodes\n",
        "\n",
        "    # Test whether the feature vector length is divisible by number of electrodes\n",
        "    assert features.shape[1] % nElectrodes == 0\n",
        "    n_colors = features.shape[1] // nElectrodes\n",
        "    for c in range(n_colors):\n",
        "        feat_array_temp.append(features[:, c * nElectrodes : nElectrodes * (c+1)])\n",
        "    if augment:\n",
        "        if pca:\n",
        "            for c in range(n_colors):\n",
        "                feat_array_temp[c] = augment_EEG(feat_array_temp[c], std_mult, pca=True, n_components=n_components)\n",
        "        else:\n",
        "            for c in range(n_colors):\n",
        "                feat_array_temp[c] = augment_EEG(feat_array_temp[c], std_mult, pca=False, n_components=n_components)\n",
        "    n_samples = features.shape[0]\n",
        "\n",
        "    # Interpolate the values\n",
        "    grid_x, grid_y = np.mgrid[\n",
        "                     min(locs[:, 0]):max(locs[:, 0]):n_gridpoints*1j,\n",
        "                     min(locs[:, 1]):max(locs[:, 1]):n_gridpoints*1j\n",
        "                     ]\n",
        "    temp_interp = []\n",
        "    for c in range(n_colors):\n",
        "        temp_interp.append(np.zeros([n_samples, n_gridpoints, n_gridpoints]))\n",
        "\n",
        "    # Generate edgeless images\n",
        "    if edgeless:\n",
        "        min_x, min_y = np.min(locs, axis=0)\n",
        "        max_x, max_y = np.max(locs, axis=0)\n",
        "        locs = np.append(locs, np.array([[min_x, min_y], [min_x, max_y], [max_x, min_y], [max_x, max_y]]), axis=0)\n",
        "        for c in range(n_colors):\n",
        "            feat_array_temp[c] = np.append(feat_array_temp[c], np.zeros((n_samples, 4)), axis=1)\n",
        "\n",
        "    # Interpolating\n",
        "    for i in range(n_samples):\n",
        "        for c in range(n_colors):\n",
        "            temp_interp[c][i, :, :] = griddata(locs, feat_array_temp[c][i, :], (grid_x, grid_y),\n",
        "                                               method='cubic', fill_value=np.nan)\n",
        "        print('Interpolating {0}/{1}\\r'.format(i + 1, n_samples), end='\\r')\n",
        "\n",
        "    # Normalizing\n",
        "    for c in range(n_colors):\n",
        "        if normalize:\n",
        "            temp_interp[c][~np.isnan(temp_interp[c])] = \\\n",
        "                scale(temp_interp[c][~np.isnan(temp_interp[c])])\n",
        "        temp_interp[c] = np.nan_to_num(temp_interp[c])\n",
        "    return np.swapaxes(np.asarray(temp_interp), 0, 1)     # swap axes to have [samples, colors, W, H]\n",
        "\n",
        "def reformatInput(data, labels, indices):\n",
        "    \"\"\"\n",
        "    Receives the indices for train and test datasets.\n",
        "    param indices: tuple of (train, test) index numbers\n",
        "    Outputs the train, validation, and test data and label datasets.\n",
        "    \"\"\"\n",
        "    np.random.shuffle(indices[0])\n",
        "    np.random.shuffle(indices[0])\n",
        "    trainIndices = indices[0][len(indices[1]):]\n",
        "    validIndices = indices[0][:len(indices[1])]\n",
        "    testIndices = indices[1]\n",
        "\n",
        "    return [(data[trainIndices], np.squeeze(labels[trainIndices]).astype(np.int32)),\n",
        "            (data[validIndices], np.squeeze(labels[validIndices]).astype(np.int32)),\n",
        "            (data[testIndices], np.squeeze(labels[testIndices]).astype(np.int32))]\n",
        "\n",
        "\n",
        "\n",
        "def print_statistics(y_test, y_test_predict, y_val=None, y_val_predict=None):\n",
        "  if y_val is not None and y_val_predict is not None:\n",
        "    print('Validation Accuracy score: ', accuracy_score(y_val, y_val_predict))\n",
        "  print('Test Accuracy score: ', accuracy_score(y_test, y_test_predict))\n",
        "  print('Test Precision score: ', precision_score(y_test, y_test_predict, average=None))\n",
        "  print('Test Recall score: ', recall_score(y_test, y_test_predict, average=None))\n",
        "  print('Test F1 score: ', f1_score(y_test, y_test_predict, average=None))\n",
        "\n",
        "def load_data():\n",
        "  # Load electrode locations\n",
        "  print('Loading data...')\n",
        "  locs = scipy.io.loadmat('Sample data/Neuroscan_locs_orig.mat')\n",
        "  locs_3d = locs['A']\n",
        "  locs_2d = []\n",
        "  # Convert to 2D\n",
        "  for e in locs_3d:\n",
        "      locs_2d.append(azim_proj(e))\n",
        "\n",
        "  feats = scipy.io.loadmat('Sample data/FeatureMat_timeWin.mat')['features']\n",
        "  subj_nums = np.squeeze(scipy.io.loadmat('Sample data/trials_subNums.mat')['subjectNum'])\n",
        "\n",
        "  # Leave-Subject-Out cross validation\n",
        "  fold_pairs = [] # 13 arrays each of which contain 2 arrays: 1 holds indices of 1 subject and the other array holds the rest indices\n",
        "  for i in np.unique(subj_nums):\n",
        "      ts = subj_nums == i\n",
        "      tr = np.squeeze(np.nonzero(np.bitwise_not(ts)))\n",
        "      ts = np.squeeze(np.nonzero(ts))\n",
        "      np.random.shuffle(tr)  # Shuffle indices\n",
        "      np.random.shuffle(ts)\n",
        "      fold_pairs.append((tr, ts))\n",
        "  return feats, subj_nums, fold_pairs, locs_2d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYLF9OzaUjkV",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx6BORYOVfcY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad7393af-5dc9-4d13-dc1f-38792a2982eb"
      },
      "source": [
        "feats, subj_nums, fold_pairs, locs_2d = load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1nJR9tvWBId",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Label balance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW2Dfthe7WIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "884f4a36-0fdd-43bc-cb0f-c51acb4ddc85"
      },
      "source": [
        "labels, sample_numbers = np.unique(feats[:, -1], return_counts=True)\n",
        "label_distributions = zip(labels, np.round(sample_numbers* 100 / sum(sample_numbers), 1))\n",
        "print(\"Label\\tPercentage\")\n",
        "for label_distribution in label_distributions:\n",
        "  print(\"{}\\t{}%\".format(label_distribution[0], label_distribution[1]))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label\tPercentage\n",
            "1.0\t28.4%\n",
            "2.0\t26.8%\n",
            "3.0\t24.0%\n",
            "4.0\t20.9%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SWEMTQzXDEo",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Generating images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_JHbajv8d0h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1401775-5ea9-4475-d34f-c04d0541de3f"
      },
      "source": [
        "# Find the average response over time windows\n",
        "av_feats = reduce(lambda x, y: x + y, [feats[:, i * 192 : (i + 1) * 192] for i in range(feats.shape[1] // 192)])\n",
        "av_feats = av_feats / (feats.shape[1] / 192)\n",
        "images = gen_images(np.array(locs_2d), av_feats, 32, normalize=True)\n",
        "images = np.transpose(images, (0, 3, 2, 1))\n",
        "images.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2670, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ALhZYOxYqCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bdc86610-b3f2-4011-9ae1-ce56710bff83"
      },
      "source": [
        "images_timewin = np.array([gen_images(np.array(locs_2d), feats[:, i * 192:(i + 1) * 192], 32, normalize=True) for i in range(feats.shape[1] // 192)])\n",
        "images_timewin = np.transpose(images_timewin, (1, 0, 3, 4, 2))\n",
        "images_timewin.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2670, 7, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTWijSLBBa7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76f8b7bf-a3bd-4988-9528-56be97f3f0d4"
      },
      "source": [
        "labels = np.squeeze(feats[:, -1]) - 1\n",
        "n_classes = len(np.unique(labels))\n",
        "print('Number of classes =', n_classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of classes = 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgfJVtnfdjG0",
        "colab_type": "text"
      },
      "source": [
        "# 3. Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5fgP9HSaMHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model_builder, images, labels, fold_pairs, epochs=10, batch_size=32, callbacks=[], verbose=0, fold_verbose=0):\n",
        "  mean_val_score = 0\n",
        "  mean_test_score = 0\n",
        "  model = model_builder()\n",
        "\n",
        "  for i in range(len(fold_pairs)):\n",
        "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = reformatInput(images, labels, fold_pairs[i])\n",
        "    model.fit(X_train, y_train, verbose=fold_verbose, epochs=epochs, batch_size=batch_size, \n",
        "              validation_data=(X_val, y_val), \n",
        "              callbacks=callbacks)\n",
        "    y_test_predict = np.argmax(model.predict(X_test), axis=1)\n",
        "    y_val_predict = np.argmax(model.predict(X_val), axis=1)\n",
        "\n",
        "    val_accuracy_score = accuracy_score(y_val, y_val_predict)\n",
        "    test_accuracy_score = accuracy_score(y_test, y_test_predict)\n",
        "\n",
        "    mean_val_score += val_accuracy_score\n",
        "    mean_test_score += test_accuracy_score\n",
        "\n",
        "    if verbose >= 2:\n",
        "      print('===========Fold {}/{}==========='.format(i + 1, len(fold_pairs)))\n",
        "      print('Validation Accuracy score: ', val_accuracy_score)\n",
        "      print('Test Accuracy score: ', test_accuracy_score)\n",
        "    if verbose == 3:\n",
        "      print('Test Precision score: ', precision_score(y_test, y_test_predict, average=None))\n",
        "      print('Test Recall score: ', recall_score(y_test, y_test_predict, average=None))\n",
        "      print('Test F1 score: ', f1_score(y_test, y_test_predict, average=None))\n",
        "\n",
        "  if verbose >= 1:\n",
        "    print('\\nMean validation accuracy score: ', mean_val_score / len(fold_pairs))\n",
        "    print('Mean test accuracy score: ', mean_test_score / len(fold_pairs))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mwUj-LxdvQq",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 ConvNet Arch. A\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04-eCAodHKgR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "2ee6fd0e-9767-4d51-ffe5-64504fa7a9dc"
      },
      "source": [
        "def conv_net_A():\n",
        "  model = Sequential([\n",
        "      Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "      Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "      MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "      Flatten(),\n",
        "      Dropout(0.5),\n",
        "      Dense(512, activation='relu'),\n",
        "      Dropout(0.5),\n",
        "      Dense(n_classes, activation='softmax')\n",
        "      ]    \n",
        "  )\n",
        "\n",
        "  adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "  model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "train_model(conv_net_A, images, labels, fold_pairs, epochs=10, callbacks=[EarlyStopping(patience=10)], verbose=2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Fold 1/13===========\n",
            "Validation Accuracy score:  0.972972972972973\n",
            "Test Accuracy score:  0.5135135135135135\n",
            "===========Fold 2/13===========\n",
            "Validation Accuracy score:  0.9528301886792453\n",
            "Test Accuracy score:  0.7216981132075472\n",
            "===========Fold 3/13===========\n",
            "Validation Accuracy score:  0.9547738693467337\n",
            "Test Accuracy score:  0.9748743718592965\n",
            "===========Fold 4/13===========\n",
            "Validation Accuracy score:  0.9353233830845771\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 5/13===========\n",
            "Validation Accuracy score:  0.9132653061224489\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 6/13===========\n",
            "Validation Accuracy score:  0.945273631840796\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 7/13===========\n",
            "Validation Accuracy score:  0.9481865284974094\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 8/13===========\n",
            "Validation Accuracy score:  0.9504950495049505\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 9/13===========\n",
            "Validation Accuracy score:  0.9523809523809523\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 10/13===========\n",
            "Validation Accuracy score:  0.9244444444444444\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 11/13===========\n",
            "Validation Accuracy score:  0.9447004608294931\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 12/13===========\n",
            "Validation Accuracy score:  0.9760765550239234\n",
            "Test Accuracy score:  0.7559808612440191\n",
            "===========Fold 13/13===========\n",
            "Validation Accuracy score:  0.9954545454545455\n",
            "Test Accuracy score:  0.7181818181818181\n",
            "\n",
            "Mean validation accuracy score:  0.9512444529371149\n",
            "Mean test accuracy score:  0.8987883598466304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO5NWUS3iRoD",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 ConvNet Arch. B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AZ_fDd3HND4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "b5978272-d23a-4339-9ac2-391aacc6714f"
      },
      "source": [
        "def conv_net_B():\n",
        "  model = Sequential([\n",
        "      Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "      Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "      MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "      Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "      Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "      MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "      Flatten(),\n",
        "      Dropout(0.5),\n",
        "      Dense(512, activation='relu'),\n",
        "      Dropout(0.5),\n",
        "      Dense(n_classes, activation='softmax')  \n",
        "      ]\n",
        "  )\n",
        "\n",
        "  adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "  model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "train_model(conv_net_B, images, labels, fold_pairs, epochs=10, callbacks=[EarlyStopping(patience=10)], verbose=2)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Fold 1/13===========\n",
            "Validation Accuracy score:  0.9459459459459459\n",
            "Test Accuracy score:  0.4972972972972973\n",
            "===========Fold 2/13===========\n",
            "Validation Accuracy score:  0.9339622641509434\n",
            "Test Accuracy score:  0.6933962264150944\n",
            "===========Fold 3/13===========\n",
            "Validation Accuracy score:  0.9447236180904522\n",
            "Test Accuracy score:  0.9698492462311558\n",
            "===========Fold 4/13===========\n",
            "Validation Accuracy score:  0.9502487562189055\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 5/13===========\n",
            "Validation Accuracy score:  0.9336734693877551\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 6/13===========\n",
            "Validation Accuracy score:  0.945273631840796\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 7/13===========\n",
            "Validation Accuracy score:  0.9326424870466321\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 8/13===========\n",
            "Validation Accuracy score:  0.9554455445544554\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 9/13===========\n",
            "Validation Accuracy score:  0.9571428571428572\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 10/13===========\n",
            "Validation Accuracy score:  0.9288888888888889\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 11/13===========\n",
            "Validation Accuracy score:  0.9631336405529954\n",
            "Test Accuracy score:  0.9907834101382489\n",
            "===========Fold 12/13===========\n",
            "Validation Accuracy score:  0.9760765550239234\n",
            "Test Accuracy score:  0.7559808612440191\n",
            "===========Fold 13/13===========\n",
            "Validation Accuracy score:  0.9818181818181818\n",
            "Test Accuracy score:  0.6636363636363637\n",
            "\n",
            "Mean validation accuracy score:  0.9499212185125177\n",
            "Mean test accuracy score:  0.8900725696124753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g9MG97Al6HB",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 ConvNet Arch. C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5e3tMTzHPmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "cf2b2048-d9ab-48a6-ecde-dad819f42107"
      },
      "source": [
        "def conv_net_C():\n",
        "  model = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(n_classes, activation='softmax')\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "  model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "train_model(conv_net_C, images, labels, fold_pairs, epochs=10, callbacks=[EarlyStopping(patience=10)], verbose=2)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Fold 1/13===========\n",
            "Validation Accuracy score:  0.9405405405405406\n",
            "Test Accuracy score:  0.5513513513513514\n",
            "===========Fold 2/13===========\n",
            "Validation Accuracy score:  0.9433962264150944\n",
            "Test Accuracy score:  0.7735849056603774\n",
            "===========Fold 3/13===========\n",
            "Validation Accuracy score:  0.914572864321608\n",
            "Test Accuracy score:  0.9849246231155779\n",
            "===========Fold 4/13===========\n",
            "Validation Accuracy score:  0.9303482587064676\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 5/13===========\n",
            "Validation Accuracy score:  0.9336734693877551\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 6/13===========\n",
            "Validation Accuracy score:  0.9402985074626866\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 7/13===========\n",
            "Validation Accuracy score:  0.9637305699481865\n",
            "Test Accuracy score:  0.9948186528497409\n",
            "===========Fold 8/13===========\n",
            "Validation Accuracy score:  0.9752475247524752\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 9/13===========\n",
            "Validation Accuracy score:  0.9571428571428572\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 10/13===========\n",
            "Validation Accuracy score:  0.9777777777777777\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 11/13===========\n",
            "Validation Accuracy score:  0.9493087557603687\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 12/13===========\n",
            "Validation Accuracy score:  0.9760765550239234\n",
            "Test Accuracy score:  0.7511961722488039\n",
            "===========Fold 13/13===========\n",
            "Validation Accuracy score:  0.9863636363636363\n",
            "Test Accuracy score:  0.5818181818181818\n",
            "\n",
            "Mean validation accuracy score:  0.9529598110464135\n",
            "Mean test accuracy score:  0.8952072220803102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrGVwbB3l-Nc",
        "colab_type": "text"
      },
      "source": [
        "## 3.4 ConvNet Arch. D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFne5_dxHToQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "d8fe9f6d-76fd-4841-966f-df89a5f72063"
      },
      "source": [
        "def conv_net_D():\n",
        "  model = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(n_classes, activation='softmax')                \n",
        "    ]    \n",
        "  )\n",
        "\n",
        "\n",
        "  adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "  model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "train_model(conv_net_D, images, labels, fold_pairs, epochs=10, callbacks=[EarlyStopping(patience=10)], verbose=2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Fold 1/13===========\n",
            "Validation Accuracy score:  0.9405405405405406\n",
            "Test Accuracy score:  0.5837837837837838\n",
            "===========Fold 2/13===========\n",
            "Validation Accuracy score:  0.9433962264150944\n",
            "Test Accuracy score:  0.75\n",
            "===========Fold 3/13===========\n",
            "Validation Accuracy score:  0.9346733668341709\n",
            "Test Accuracy score:  0.9095477386934674\n",
            "===========Fold 4/13===========\n",
            "Validation Accuracy score:  0.945273631840796\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 5/13===========\n",
            "Validation Accuracy score:  0.9438775510204082\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 6/13===========\n",
            "Validation Accuracy score:  0.9353233830845771\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 7/13===========\n",
            "Validation Accuracy score:  0.9222797927461139\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 8/13===========\n",
            "Validation Accuracy score:  0.9653465346534653\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 9/13===========\n",
            "Validation Accuracy score:  0.9428571428571428\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 10/13===========\n",
            "Validation Accuracy score:  0.9511111111111111\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 11/13===========\n",
            "Validation Accuracy score:  0.9400921658986175\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 12/13===========\n",
            "Validation Accuracy score:  0.9521531100478469\n",
            "Test Accuracy score:  0.7464114832535885\n",
            "===========Fold 13/13===========\n",
            "Validation Accuracy score:  0.9590909090909091\n",
            "Test Accuracy score:  0.6181818181818182\n",
            "\n",
            "Mean validation accuracy score:  0.9443088820108302\n",
            "Mean test accuracy score:  0.8929172941471275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vi0JBP9mCLA",
        "colab_type": "text"
      },
      "source": [
        "## 3.5 ConvNet+Maxpool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Poqno0KddnTl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "cd553e62-d490-476f-e91e-32645ba1b7e0"
      },
      "source": [
        "def conv_net_max_pool():\n",
        "  model = Sequential([\n",
        "    TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(7, 32, 32, 3))),\n",
        "    TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=2)),\n",
        "    TimeDistributed(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=2)),\n",
        "    TimeDistributed(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=2)),\n",
        "    Reshape((7, 4*4*128)),\n",
        "    MaxPooling1D(pool_size=7, strides=1, data_format='channels_last'),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(n_classes, activation='softmax')                  \n",
        "    ]    \n",
        "  )\n",
        "\n",
        "\n",
        "  adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "  model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "train_model(conv_net_max_pool, images_timewin, labels, fold_pairs, epochs=10, callbacks=[EarlyStopping(patience=10)], verbose=2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Fold 1/13===========\n",
            "Validation Accuracy score:  0.9567567567567568\n",
            "Test Accuracy score:  0.572972972972973\n",
            "===========Fold 2/13===========\n",
            "Validation Accuracy score:  0.9528301886792453\n",
            "Test Accuracy score:  0.6933962264150944\n",
            "===========Fold 3/13===========\n",
            "Validation Accuracy score:  0.8994974874371859\n",
            "Test Accuracy score:  0.9698492462311558\n",
            "===========Fold 4/13===========\n",
            "Validation Accuracy score:  0.9651741293532339\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 5/13===========\n",
            "Validation Accuracy score:  0.9387755102040817\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 6/13===========\n",
            "Validation Accuracy score:  0.9402985074626866\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 7/13===========\n",
            "Validation Accuracy score:  0.9844559585492227\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 8/13===========\n",
            "Validation Accuracy score:  0.9603960396039604\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 9/13===========\n",
            "Validation Accuracy score:  0.9619047619047619\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 10/13===========\n",
            "Validation Accuracy score:  0.9555555555555556\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 11/13===========\n",
            "Validation Accuracy score:  0.9354838709677419\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 12/13===========\n",
            "Validation Accuracy score:  0.9712918660287081\n",
            "Test Accuracy score:  0.7511961722488039\n",
            "===========Fold 13/13===========\n",
            "Validation Accuracy score:  0.9681818181818181\n",
            "Test Accuracy score:  0.7045454545454546\n",
            "\n",
            "Mean validation accuracy score:  0.9531232654373044\n",
            "Mean test accuracy score:  0.8993815440318063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySsA1y7cmM1K",
        "colab_type": "text"
      },
      "source": [
        "## 3.6 ConvNet+1D-Conv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKQKzER0fI1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "452a5f20-b82a-4aa8-d07f-c2c5f6ead102"
      },
      "source": [
        "def conv_net_1d_conv():\n",
        "  model= Sequential([\n",
        "    TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(7, 32, 32, 3))),\n",
        "    TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))),\n",
        "    TimeDistributed(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))),\n",
        "    TimeDistributed(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))),\n",
        "    TimeDistributed(Flatten()),\n",
        "    Conv1D(filters=64, kernel_size=3, strides=1, activation='relu', padding='valid'),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(n_classes, activation='softmax'),\n",
        "    ]    \n",
        "  )\n",
        "\n",
        "  adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "  model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "train_model(conv_net_1d_conv, images_timewin, labels, fold_pairs, epochs=40, callbacks=[EarlyStopping(patience=10)], verbose=2)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Fold 1/13===========\n",
            "Validation Accuracy score:  0.9621621621621622\n",
            "Test Accuracy score:  0.5459459459459459\n",
            "===========Fold 2/13===========\n",
            "Validation Accuracy score:  0.9386792452830188\n",
            "Test Accuracy score:  0.7735849056603774\n",
            "===========Fold 3/13===========\n",
            "Validation Accuracy score:  0.964824120603015\n",
            "Test Accuracy score:  0.9949748743718593\n",
            "===========Fold 4/13===========\n",
            "Validation Accuracy score:  0.9751243781094527\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 5/13===========\n",
            "Validation Accuracy score:  0.9693877551020408\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 6/13===========\n",
            "Validation Accuracy score:  0.9701492537313433\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 7/13===========\n",
            "Validation Accuracy score:  0.9689119170984456\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 8/13===========\n",
            "Validation Accuracy score:  0.9405940594059405\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 9/13===========\n",
            "Validation Accuracy score:  0.9333333333333333\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 10/13===========\n",
            "Validation Accuracy score:  0.9688888888888889\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 11/13===========\n",
            "Validation Accuracy score:  0.9585253456221198\n",
            "Test Accuracy score:  0.9953917050691244\n",
            "===========Fold 12/13===========\n",
            "Validation Accuracy score:  0.9760765550239234\n",
            "Test Accuracy score:  0.7559808612440191\n",
            "===========Fold 13/13===========\n",
            "Validation Accuracy score:  0.9636363636363636\n",
            "Test Accuracy score:  0.5636363636363636\n",
            "\n",
            "Mean validation accuracy score:  0.9607917983076959\n",
            "Mean test accuracy score:  0.8945780504559763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkGjkQOgmxqY",
        "colab_type": "text"
      },
      "source": [
        "## 3.7 ConvNet+LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgR_UpHtzuMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "f2d7aa0b-4c52-4639-dfd4-1a2d887e3d24"
      },
      "source": [
        "class WeightClip(Constraint):\n",
        "    '''Clips the weights by value c\n",
        "    '''\n",
        "    def __init__(self, c):\n",
        "        self.c = c\n",
        "\n",
        "    def __call__(self, p):\n",
        "        return tf.keras.backend.clip(p, -self.c, self.c)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'name': self.__class__.__name__,\n",
        "                'c': self.c}\n",
        "\n",
        "def conv_net_lstm():\n",
        "  model= Sequential([\n",
        "    TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(7, 32, 32, 3))),\n",
        "    TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))),\n",
        "    TimeDistributed(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))),\n",
        "    TimeDistributed(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')),\n",
        "    TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))),\n",
        "    TimeDistributed(Flatten()),\n",
        "    LSTM(128, activation='tanh', kernel_constraint=WeightClip(100)), \n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(n_classes, activation='softmax'),\n",
        "    ]    \n",
        "  )\n",
        "\n",
        "  #changed learning rate to 0.0001, otherwise doesn't converge\n",
        "  adam_optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999)\n",
        "  model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "train_model(conv_net_lstm, images_timewin, labels, fold_pairs, epochs=10, callbacks=[EarlyStopping(patience=10)], verbose=2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Fold 1/13===========\n",
            "Validation Accuracy score:  0.9675675675675676\n",
            "Test Accuracy score:  0.5567567567567567\n",
            "===========Fold 2/13===========\n",
            "Validation Accuracy score:  0.9481132075471698\n",
            "Test Accuracy score:  0.7547169811320755\n",
            "===========Fold 3/13===========\n",
            "Validation Accuracy score:  0.9447236180904522\n",
            "Test Accuracy score:  0.9246231155778895\n",
            "===========Fold 4/13===========\n",
            "Validation Accuracy score:  0.9203980099502488\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 5/13===========\n",
            "Validation Accuracy score:  0.9540816326530612\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 6/13===========\n",
            "Validation Accuracy score:  0.9353233830845771\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 7/13===========\n",
            "Validation Accuracy score:  0.9326424870466321\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 8/13===========\n",
            "Validation Accuracy score:  0.9702970297029703\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 9/13===========\n",
            "Validation Accuracy score:  0.9333333333333333\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 10/13===========\n",
            "Validation Accuracy score:  0.96\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 11/13===========\n",
            "Validation Accuracy score:  0.967741935483871\n",
            "Test Accuracy score:  1.0\n",
            "===========Fold 12/13===========\n",
            "Validation Accuracy score:  0.9617224880382775\n",
            "Test Accuracy score:  0.7559808612440191\n",
            "===========Fold 13/13===========\n",
            "Validation Accuracy score:  0.9863636363636363\n",
            "Test Accuracy score:  0.6818181818181818\n",
            "\n",
            "Mean validation accuracy score:  0.9524852560662921\n",
            "Mean test accuracy score:  0.8979919920406864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD-SUuniqAAv",
        "colab_type": "text"
      },
      "source": [
        "## 3.8 ConvNet+LSTM/1D-Conv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfO3VjrkUmLr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6321fd5-a388-4c0a-d85a-204485fa6e60"
      },
      "source": [
        "def conv_net_lstm_1d_conv():\n",
        "  input_layer = Input(shape=(7, 32, 32, 3))\n",
        "  conv2d = TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')) (input_layer)\n",
        "  conv2d = TimeDistributed(BatchNormalization()) (conv2d)\n",
        "  conv2d = TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')) (conv2d)\n",
        "  conv2d = TimeDistributed(BatchNormalization()) (conv2d)\n",
        "  conv2d = TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')) (conv2d)\n",
        "  conv2d = TimeDistributed(BatchNormalization()) (conv2d)\n",
        "  conv2d = TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')) (conv2d)\n",
        "  maxpool2d = TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) (conv2d)\n",
        "  maxpool2d = TimeDistributed(BatchNormalization()) (maxpool2d)\n",
        "  conv2d = TimeDistributed(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')) (maxpool2d)\n",
        "  conv2d = TimeDistributed(BatchNormalization()) (conv2d)\n",
        "  conv2d = TimeDistributed(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')) (conv2d)\n",
        "  maxpool2d = TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) (conv2d)\n",
        "  maxpool2d = TimeDistributed(BatchNormalization()) (maxpool2d)\n",
        "  conv2d = TimeDistributed(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')) (maxpool2d)\n",
        "  maxpool2d = TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) (conv2d)\n",
        "  maxpool2d = TimeDistributed(BatchNormalization()) (maxpool2d)\n",
        "  maxpool2d = TimeDistributed(Flatten()) (maxpool2d)\n",
        "\n",
        "  lstm = LSTM(128, activation='tanh', kernel_constraint=WeightClip(100)) (maxpool2d)\n",
        "\n",
        "  conv1d = Conv1D(filters=64, kernel_size=3, strides=1, activation='relu', padding='valid') (maxpool2d)\n",
        "  conv1d = Flatten() (conv1d)\n",
        "\n",
        "  concat_layer = Concatenate()([lstm, conv1d])\n",
        "  concat_layer = BatchNormalization() (concat_layer)\n",
        "\n",
        "  layer = Dropout(0.5) (concat_layer)\n",
        "  layer = Dense(256, activation='relu') (layer)\n",
        "  layer = BatchNormalization() (layer)\n",
        "  layer = Dropout(0.5) (layer)\n",
        "  output_layer = Dense(n_classes, activation='softmax') (layer)\n",
        "\n",
        "  model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "\n",
        "  adam_optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999)\n",
        "  model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "train_model(conv_net_lstm_1d_conv, images_timewin, labels, fold_pairs, epochs=6, callbacks=[EarlyStopping(patience=6)], verbose=3)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========Fold 1/13===========\n",
            "Validation Accuracy score:  0.8540540540540541\n",
            "Test Accuracy score:  0.9027027027027027\n",
            "Test Precision score:  [0.93103448 0.88461538 0.86538462 0.95652174]\n",
            "Test Recall score:  [0.94736842 0.95833333 0.95744681 0.66666667]\n",
            "Test F1 score:  [0.93913043 0.92       0.90909091 0.78571429]\n",
            "===========Fold 2/13===========\n",
            "Validation Accuracy score:  0.9292452830188679\n",
            "Test Accuracy score:  0.839622641509434\n",
            "Test Precision score:  [0.84210526 0.6        1.         1.        ]\n",
            "Test Recall score:  [1.         0.73333333 0.61111111 0.97959184]\n",
            "Test F1 score:  [0.91428571 0.66       0.75862069 0.98969072]\n",
            "===========Fold 3/13===========\n",
            "Validation Accuracy score:  0.949748743718593\n",
            "Test Accuracy score:  0.949748743718593\n",
            "Test Precision score:  [0.87301587 1.         0.97727273 0.97916667]\n",
            "Test Recall score:  [1.         0.81481481 1.         1.        ]\n",
            "Test F1 score:  [0.93220339 0.89795918 0.98850575 0.98947368]\n",
            "===========Fold 4/13===========\n",
            "Validation Accuracy score:  0.9502487562189055\n",
            "Test Accuracy score:  1.0\n",
            "Test Precision score:  [1. 1. 1. 1.]\n",
            "Test Recall score:  [1. 1. 1. 1.]\n",
            "Test F1 score:  [1. 1. 1. 1.]\n",
            "===========Fold 5/13===========\n",
            "Validation Accuracy score:  0.9336734693877551\n",
            "Test Accuracy score:  1.0\n",
            "Test Precision score:  [1. 1. 1. 1.]\n",
            "Test Recall score:  [1. 1. 1. 1.]\n",
            "Test F1 score:  [1. 1. 1. 1.]\n",
            "===========Fold 6/13===========\n",
            "Validation Accuracy score:  0.945273631840796\n",
            "Test Accuracy score:  1.0\n",
            "Test Precision score:  [1. 1. 1. 1.]\n",
            "Test Recall score:  [1. 1. 1. 1.]\n",
            "Test F1 score:  [1. 1. 1. 1.]\n",
            "===========Fold 7/13===========\n",
            "Validation Accuracy score:  0.9585492227979274\n",
            "Test Accuracy score:  1.0\n",
            "Test Precision score:  [1. 1. 1. 1.]\n",
            "Test Recall score:  [1. 1. 1. 1.]\n",
            "Test F1 score:  [1. 1. 1. 1.]\n",
            "===========Fold 8/13===========\n",
            "Validation Accuracy score:  0.9851485148514851\n",
            "Test Accuracy score:  1.0\n",
            "Test Precision score:  [1. 1. 1. 1.]\n",
            "Test Recall score:  [1. 1. 1. 1.]\n",
            "Test F1 score:  [1. 1. 1. 1.]\n",
            "===========Fold 9/13===========\n",
            "Validation Accuracy score:  0.9523809523809523\n",
            "Test Accuracy score:  1.0\n",
            "Test Precision score:  [1. 1. 1. 1.]\n",
            "Test Recall score:  [1. 1. 1. 1.]\n",
            "Test F1 score:  [1. 1. 1. 1.]\n",
            "===========Fold 10/13===========\n",
            "Validation Accuracy score:  0.9511111111111111\n",
            "Test Accuracy score:  1.0\n",
            "Test Precision score:  [1. 1. 1. 1.]\n",
            "Test Recall score:  [1. 1. 1. 1.]\n",
            "Test F1 score:  [1. 1. 1. 1.]\n",
            "===========Fold 11/13===========\n",
            "Validation Accuracy score:  0.9585253456221198\n",
            "Test Accuracy score:  1.0\n",
            "Test Precision score:  [1. 1. 1. 1.]\n",
            "Test Recall score:  [1. 1. 1. 1.]\n",
            "Test F1 score:  [1. 1. 1. 1.]\n",
            "===========Fold 12/13===========\n",
            "Validation Accuracy score:  0.9760765550239234\n",
            "Test Accuracy score:  0.7559808612440191\n",
            "Test Precision score:  [1.         1.         0.50485437 1.        ]\n",
            "Test Recall score:  [1.         0.08928571 1.         1.        ]\n",
            "Test F1 score:  [1.         0.16393443 0.67096774 1.        ]\n",
            "===========Fold 13/13===========\n",
            "Validation Accuracy score:  0.9727272727272728\n",
            "Test Accuracy score:  0.7318181818181818\n",
            "Test Precision score:  [1.         0.         0.47787611 1.        ]\n",
            "Test Recall score:  [1. 0. 1. 1.]\n",
            "Test F1 score:  [1.         0.         0.64670659 1.        ]\n",
            "\n",
            "Mean validation accuracy score:  0.9474433009810586\n",
            "Mean test accuracy score:  0.936913317768687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UyKQVCE_RRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}